{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216f70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49c3160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>review_count_x</th>\n",
       "      <th>is_open</th>\n",
       "      <th>RestaurantsTakeOut</th>\n",
       "      <th>NoiseLevel</th>\n",
       "      <th>Caters</th>\n",
       "      <th>RestaurantsReservations</th>\n",
       "      <th>BusinessAcceptsCreditCards</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yPSejq3_erxo9zdVYTBnZA</td>\n",
       "      <td>93101</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3834</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>average</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057698</td>\n",
       "      <td>-0.040529</td>\n",
       "      <td>-0.099978</td>\n",
       "      <td>-0.004862</td>\n",
       "      <td>-0.025210</td>\n",
       "      <td>-0.086385</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.110364</td>\n",
       "      <td>0.075793</td>\n",
       "      <td>-0.107090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yPSejq3_erxo9zdVYTBnZA</td>\n",
       "      <td>93101</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3834</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>average</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082968</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>-0.045763</td>\n",
       "      <td>-0.066925</td>\n",
       "      <td>0.020732</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>0.024235</td>\n",
       "      <td>0.014555</td>\n",
       "      <td>-0.030172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yPSejq3_erxo9zdVYTBnZA</td>\n",
       "      <td>93101</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3834</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>average</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010111</td>\n",
       "      <td>-0.101000</td>\n",
       "      <td>-0.014174</td>\n",
       "      <td>0.121339</td>\n",
       "      <td>-0.055661</td>\n",
       "      <td>-0.162740</td>\n",
       "      <td>0.103488</td>\n",
       "      <td>0.138003</td>\n",
       "      <td>-0.013085</td>\n",
       "      <td>-0.109602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yPSejq3_erxo9zdVYTBnZA</td>\n",
       "      <td>93101</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3834</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>average</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025030</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>-0.086865</td>\n",
       "      <td>-0.004529</td>\n",
       "      <td>-0.010611</td>\n",
       "      <td>-0.091941</td>\n",
       "      <td>-0.046247</td>\n",
       "      <td>0.117090</td>\n",
       "      <td>0.039307</td>\n",
       "      <td>-0.040667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yPSejq3_erxo9zdVYTBnZA</td>\n",
       "      <td>93101</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3834</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>average</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036952</td>\n",
       "      <td>-0.054311</td>\n",
       "      <td>-0.142655</td>\n",
       "      <td>-0.065425</td>\n",
       "      <td>0.067039</td>\n",
       "      <td>-0.055701</td>\n",
       "      <td>-0.085879</td>\n",
       "      <td>0.052690</td>\n",
       "      <td>0.010894</td>\n",
       "      <td>-0.083118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162278</th>\n",
       "      <td>vyxxsn2l6ELF2Yoxr6BWcw</td>\n",
       "      <td>93108</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NotStated</td>\n",
       "      <td>average</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>-0.064970</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>0.083591</td>\n",
       "      <td>-0.011485</td>\n",
       "      <td>-0.050519</td>\n",
       "      <td>-0.046918</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>-0.015228</td>\n",
       "      <td>-0.101348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162279</th>\n",
       "      <td>vyxxsn2l6ELF2Yoxr6BWcw</td>\n",
       "      <td>93108</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NotStated</td>\n",
       "      <td>average</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051642</td>\n",
       "      <td>-0.086415</td>\n",
       "      <td>-0.108635</td>\n",
       "      <td>-0.002040</td>\n",
       "      <td>0.020855</td>\n",
       "      <td>-0.020032</td>\n",
       "      <td>0.023868</td>\n",
       "      <td>0.017847</td>\n",
       "      <td>0.020405</td>\n",
       "      <td>-0.039570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162280</th>\n",
       "      <td>vyxxsn2l6ELF2Yoxr6BWcw</td>\n",
       "      <td>93108</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NotStated</td>\n",
       "      <td>average</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017672</td>\n",
       "      <td>0.065645</td>\n",
       "      <td>0.019597</td>\n",
       "      <td>-0.101516</td>\n",
       "      <td>-0.155894</td>\n",
       "      <td>0.116494</td>\n",
       "      <td>0.092330</td>\n",
       "      <td>-0.036549</td>\n",
       "      <td>-0.096109</td>\n",
       "      <td>-0.043046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162281</th>\n",
       "      <td>vyxxsn2l6ELF2Yoxr6BWcw</td>\n",
       "      <td>93108</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NotStated</td>\n",
       "      <td>average</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042752</td>\n",
       "      <td>-0.004355</td>\n",
       "      <td>-0.065961</td>\n",
       "      <td>-0.069475</td>\n",
       "      <td>-0.042288</td>\n",
       "      <td>0.091073</td>\n",
       "      <td>0.087256</td>\n",
       "      <td>0.012710</td>\n",
       "      <td>-0.026422</td>\n",
       "      <td>-0.035184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162282</th>\n",
       "      <td>vyxxsn2l6ELF2Yoxr6BWcw</td>\n",
       "      <td>93108</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NotStated</td>\n",
       "      <td>average</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031845</td>\n",
       "      <td>-0.116963</td>\n",
       "      <td>-0.023171</td>\n",
       "      <td>-0.054536</td>\n",
       "      <td>0.101728</td>\n",
       "      <td>-0.126186</td>\n",
       "      <td>-0.040101</td>\n",
       "      <td>-0.076757</td>\n",
       "      <td>0.043670</td>\n",
       "      <td>0.086427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162283 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  postal_code  stars_x  review_count_x  is_open  \\\n",
       "0       yPSejq3_erxo9zdVYTBnZA        93101      4.5            3834        1   \n",
       "1       yPSejq3_erxo9zdVYTBnZA        93101      4.5            3834        1   \n",
       "2       yPSejq3_erxo9zdVYTBnZA        93101      4.5            3834        1   \n",
       "3       yPSejq3_erxo9zdVYTBnZA        93101      4.5            3834        1   \n",
       "4       yPSejq3_erxo9zdVYTBnZA        93101      4.5            3834        1   \n",
       "...                        ...          ...      ...             ...      ...   \n",
       "162278  vyxxsn2l6ELF2Yoxr6BWcw        93108      3.0               7        0   \n",
       "162279  vyxxsn2l6ELF2Yoxr6BWcw        93108      3.0               7        0   \n",
       "162280  vyxxsn2l6ELF2Yoxr6BWcw        93108      3.0               7        0   \n",
       "162281  vyxxsn2l6ELF2Yoxr6BWcw        93108      3.0               7        0   \n",
       "162282  vyxxsn2l6ELF2Yoxr6BWcw        93108      3.0               7        0   \n",
       "\n",
       "       RestaurantsTakeOut NoiseLevel  Caters RestaurantsReservations  \\\n",
       "0                    True    average    True                   False   \n",
       "1                    True    average    True                   False   \n",
       "2                    True    average    True                   False   \n",
       "3                    True    average    True                   False   \n",
       "4                    True    average    True                   False   \n",
       "...                   ...        ...     ...                     ...   \n",
       "162278          NotStated    average   False                   False   \n",
       "162279          NotStated    average   False                   False   \n",
       "162280          NotStated    average   False                   False   \n",
       "162281          NotStated    average   False                   False   \n",
       "162282          NotStated    average   False                   False   \n",
       "\n",
       "        BusinessAcceptsCreditCards  ...        10        11        12  \\\n",
       "0                             True  ... -0.057698 -0.040529 -0.099978   \n",
       "1                             True  ... -0.082968  0.011081  0.008248   \n",
       "2                             True  ... -0.010111 -0.101000 -0.014174   \n",
       "3                             True  ... -0.025030  0.005635 -0.086865   \n",
       "4                             True  ... -0.036952 -0.054311 -0.142655   \n",
       "...                            ...  ...       ...       ...       ...   \n",
       "162278                        True  ... -0.001943 -0.064970 -0.000479   \n",
       "162279                        True  ... -0.051642 -0.086415 -0.108635   \n",
       "162280                        True  ...  0.017672  0.065645  0.019597   \n",
       "162281                        True  ...  0.042752 -0.004355 -0.065961   \n",
       "162282                        True  ... -0.031845 -0.116963 -0.023171   \n",
       "\n",
       "              13        14        15        16        17        18        19  \n",
       "0      -0.004862 -0.025210 -0.086385  0.001367  0.110364  0.075793 -0.107090  \n",
       "1      -0.045763 -0.066925  0.020732  0.022225  0.024235  0.014555 -0.030172  \n",
       "2       0.121339 -0.055661 -0.162740  0.103488  0.138003 -0.013085 -0.109602  \n",
       "3      -0.004529 -0.010611 -0.091941 -0.046247  0.117090  0.039307 -0.040667  \n",
       "4      -0.065425  0.067039 -0.055701 -0.085879  0.052690  0.010894 -0.083118  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "162278  0.083591 -0.011485 -0.050519 -0.046918 -0.000521 -0.015228 -0.101348  \n",
       "162279 -0.002040  0.020855 -0.020032  0.023868  0.017847  0.020405 -0.039570  \n",
       "162280 -0.101516 -0.155894  0.116494  0.092330 -0.036549 -0.096109 -0.043046  \n",
       "162281 -0.069475 -0.042288  0.091073  0.087256  0.012710 -0.026422 -0.035184  \n",
       "162282 -0.054536  0.101728 -0.126186 -0.040101 -0.076757  0.043670  0.086427  \n",
       "\n",
       "[162283 rows x 87 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"refined data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70e084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['business_id', 'review_id', 'user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a22c0f",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69535b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = ['postal_code', 'is_open', 'RestaurantsTakeOut', 'NoiseLevel', 'Caters', 'RestaurantsReservations',\n",
    "           'BusinessAcceptsCreditCards', 'GoodForKids', 'RestaurantsPriceRange2',\n",
    "           'OutdoorSeating', 'RestaurantsDelivery', 'HasTV', 'RestaurantsAttire',\n",
    "           'Alcohol', 'RestaurantsGoodForGroups', 'BikeParking', 'WiFi',\n",
    "           'BusinessParking_garage', 'BusinessParking_street',\n",
    "           'BusinessParking_validated', 'BusinessParking_lot',\n",
    "           'BusinessParking_valet', 'Ambience_touristy', 'Ambience_hipster',\n",
    "           'Ambience_romantic', 'Ambience_divey', 'Ambience_intimate',\n",
    "           'Ambience_trendy', 'Ambience_upscale', 'Ambience_classy',\n",
    "           'Ambience_casual', 'GoodForMeal_dessert', 'GoodForMeal_latenight',\n",
    "           'GoodForMeal_lunch', 'GoodForMeal_dinner', 'GoodForMeal_brunch',\n",
    "           'GoodForMeal_breakfast', 'category_Casual Dining & Drinks',\n",
    "           'category_Diverse Cuisine & Entertainment',\n",
    "           'category_Health & Lifestyle', 'category_Nightlife Essentials',\n",
    "           'category_Traditional Comfort Foods', 'category_Sophisticated Eats']\n",
    "num_var = ['review_count_x', 'stars_y', 'useful_x', 'funny_x', 'cool_x',\n",
    "           'review_count_y', 'useful_y', 'funny_y', 'cool_y', 'fans',\n",
    "           'average_stars', 'compliment_hot', 'compliment_more',\n",
    "           'compliment_profile', 'compliment_cute', 'compliment_list',\n",
    "           'compliment_funny', 'compliment_writer', 'compliment_photos', 'days_used',\n",
    "           '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
    "           '11', '12', '13', '14', '15', '16', '17', '18', '19']\n",
    "y = ['stars_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fab81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = pd.concat([data[cat_var].astype(str), data[num_var]], axis=1)\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoder.fit(X[cat_var])\n",
    "\n",
    "encoded_cols = encoder.get_feature_names_out(cat_var)\n",
    "X[encoded_cols] = encoder.transform(X[cat_var])\n",
    "X.drop(columns=cat_var, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b1a59",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c71bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e8a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38f16658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Training RMSE: 0.3607771023875566 Test RMSE: 0.36208198460224444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Linear Regression\n",
    "lr = make_pipeline(StandardScaler(),LinearRegression())\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train_lr = lr.predict(X_train)\n",
    "y_pred_test_lr = lr.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_train_lr = np.sqrt(mean_squared_error(y_train, y_pred_train_lr))\n",
    "rmse_test_lr = np.sqrt(mean_squared_error(y_test, y_pred_test_lr))\n",
    "print(\"Linear Regression - Training RMSE:\", rmse_train_lr, \"Test RMSE:\", rmse_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d59da9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Training RMSE: 0.46699030432245797 Test RMSE: 0.46963204292198374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# SVM Regression\n",
    "svm = make_pipeline(StandardScaler(),SVR())\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_train_svm = svm.predict(X_train)\n",
    "y_pred_test_svm = svm.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_train_svm = np.sqrt(mean_squared_error(y_train, y_pred_train_svm))\n",
    "rmse_test_svm = np.sqrt(mean_squared_error(y_test, y_pred_test_svm))\n",
    "print(\"SVM - Training RMSE:\", rmse_train_svm, \"Test RMSE:\", rmse_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9da081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Training RMSE: 0.0 Test RMSE: 0.03825538852513842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train_dt = dt.predict(X_train)\n",
    "y_pred_test_dt = dt.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_train_dt = np.sqrt(mean_squared_error(y_train, y_pred_train_dt))\n",
    "rmse_test_dt = np.sqrt(mean_squared_error(y_test, y_pred_test_dt))\n",
    "print(\"Decision Tree - Training RMSE:\", rmse_train_dt, \"Test RMSE:\", rmse_test_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f63a5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Training RMSE: 0.014143122780627036 Test RMSE: 0.038564641420874554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_train_rf = rf.predict(X_train)\n",
    "y_pred_test_rf = rf.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_train_rf = np.sqrt(mean_squared_error(y_train, y_pred_train_rf))\n",
    "rmse_test_rf = np.sqrt(mean_squared_error(y_test, y_pred_test_rf))\n",
    "print(\"Random Forest - Training RMSE:\", rmse_train_rf, \"Test RMSE:\", rmse_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "375518df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - Training RMSE: 0.4118668206368927 Test RMSE: 0.4132669314167062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# AdaBoost\n",
    "ab = AdaBoostRegressor()\n",
    "ab.fit(X_train, y_train)\n",
    "y_pred_train_ab = ab.predict(X_train)\n",
    "y_pred_test_ab = ab.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_train_ab = np.sqrt(mean_squared_error(y_train, y_pred_train_ab))\n",
    "rmse_test_ab = np.sqrt(mean_squared_error(y_test, y_pred_test_ab))\n",
    "print(\"AdaBoost - Training RMSE:\", rmse_train_ab, \"Test RMSE:\", rmse_test_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ae592b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Training RMSE: 0.06353082803286694 Test RMSE: 0.07363152346556234\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_train_xgb = xgb.predict(X_train)\n",
    "y_pred_test_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_train_xgb = np.sqrt(mean_squared_error(y_train, y_pred_train_xgb))\n",
    "rmse_test_xgb = np.sqrt(mean_squared_error(y_test, y_pred_test_xgb))\n",
    "print(\"XGBoost - Training RMSE:\", rmse_train_xgb, \"Test RMSE:\", rmse_test_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be12418d",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52bca739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with 5-Fold CV\n",
      "CV RMSE: 0.36123460830953313\n",
      "Training RMSE: 0.3607771023875566\n",
      "Test RMSE: 0.36208198460224444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Create a pipeline with a StandardScaler and Linear Regression\n",
    "pipeline_lr = make_pipeline(StandardScaler(), LinearRegression())\n",
    "\n",
    "# Perform 5-fold cross-validation to calculate CV RMSE\n",
    "cv_scores = cross_val_score(pipeline_lr, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_scores = np.sqrt(-cv_scores)\n",
    "\n",
    "# Fit the model to the training data\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set and calculate RMSE\n",
    "y_train_pred = pipeline_lr.predict(X_train)\n",
    "training_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Predict on the test set and calculate RMSE\n",
    "y_test_pred = pipeline_lr.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print the results\n",
    "print(\"Linear Regression with 5-Fold CV\")\n",
    "print(\"CV RMSE:\", np.mean(cv_rmse_scores))\n",
    "print(\"Training RMSE:\", training_rmse)\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6ea40ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "SVM - CV RMSE: 0.07781331377867416\n",
      "Training RMSE: 0.05701241026709103, Test RMSE: 0.07538246062580975\n",
      "SVM - Best Parameters: {'svr__kernel': 'rbf', 'svr__gamma': 'scale', 'svr__C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Parameter distribution\n",
    "param_distributions_svm = {\n",
    "    'svr__C': [0.1, 1, 10, 100],\n",
    "    'svr__gamma': ['scale', 'auto'],\n",
    "    'svr__kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "# SVM with RandomizedSearchCV\n",
    "svm = make_pipeline(StandardScaler(), SVR())\n",
    "randomized_search = RandomizedSearchCV(svm, param_distributions_svm, n_iter=10, scoring='neg_mean_squared_error', cv=3, verbose=1)\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = randomized_search.best_estimator_\n",
    "\n",
    "# Calculate RMSE\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"SVM - CV RMSE: {np.sqrt(-randomized_search.best_score_)}\")\n",
    "print(f\"Training RMSE: {rmse_train}, Test RMSE: {rmse_test}\")\n",
    "print(\"SVM - Best Parameters:\", randomized_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7802d850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Decision Tree - CV RMSE: 0.0507361321278938\n",
      "Training RMSE: 0.012405316432591622, Test RMSE: 0.04171990826659426\n",
      "Decision Tree - Best Parameters: {'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 40}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Parameter distribution\n",
    "param_distribution = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Decision Tree with RandomizedSearchCV\n",
    "dt = DecisionTreeRegressor()\n",
    "randomized_search = RandomizedSearchCV(dt, param_distribution, n_iter=10, scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = randomized_search.best_estimator_\n",
    "\n",
    "# Calculate RMSE\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"Decision Tree - CV RMSE: {np.sqrt(-randomized_search.best_score_)}\")\n",
    "print(f\"Training RMSE: {rmse_train}, Test RMSE: {rmse_test}\")\n",
    "print(\"Decision Tree - Best Parameters:\", randomized_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c381b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Random Forest - CV RMSE: 0.04501347068980332\n",
      "Training RMSE: 0.017577567110665927, Test RMSE: 0.03970465774480407\n",
      "Random Forest - Best Parameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Parameter distribution\n",
    "param_distribution = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Random Forest with RandomizedSearchCV\n",
    "rf = RandomForestRegressor()\n",
    "randomized_search = RandomizedSearchCV(rf, param_distribution, n_iter=10, scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = randomized_search.best_estimator_\n",
    "\n",
    "# Calculate RMSE\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"Random Forest - CV RMSE: {np.sqrt(-randomized_search.best_score_)}\")\n",
    "print(f\"Training RMSE: {rmse_train}, Test RMSE: {rmse_test}\")\n",
    "print(\"Random Forest - Best Parameters:\", randomized_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b08bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "AdaBoost - CV RMSE: 0.4049959987286703\n",
      "Training RMSE: 0.40575722861095814, Test RMSE: 0.4067168511158778\n",
      "AdaBoost - Best Parameters: {'n_estimators': 200, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Parameter distribution\n",
    "param_distribution = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# AdaBoost with RandomizedSearchCV\n",
    "ab = AdaBoostRegressor()\n",
    "randomized_search = RandomizedSearchCV(ab, param_distribution, n_iter=10, scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = randomized_search.best_estimator_\n",
    "\n",
    "# Calculate RMSE\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"AdaBoost - CV RMSE: {np.sqrt(-randomized_search.best_score_)}\")\n",
    "print(f\"Training RMSE: {rmse_train}, Test RMSE: {rmse_test}\")\n",
    "print(\"AdaBoost - Best Parameters:\", randomized_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4e584cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "XGBoost - CV RMSE: 0.049617860415837406\n",
      "Training RMSE: 0.025247711964109472, Test RMSE: 0.04787296254608612\n",
      "XGBoost - Best Parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Parameter distribution\n",
    "param_distribution = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8]\n",
    "}\n",
    "\n",
    "# XGBoost with RandomizedSearchCV\n",
    "xgb = XGBRegressor()\n",
    "randomized_search = RandomizedSearchCV(xgb, param_distribution, n_iter=10, scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = randomized_search.best_estimator_\n",
    "\n",
    "# Calculate RMSE\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"XGBoost - CV RMSE: {np.sqrt(-randomized_search.best_score_)}\")\n",
    "print(f\"Training RMSE: {rmse_train}, Test RMSE: {rmse_test}\")\n",
    "print(\"XGBoost - Best Parameters:\", randomized_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ba335",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90d4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models = [\n",
    "    ('linear_regression', LinearRegression()),\n",
    "    ('decision_tree', DecisionTreeRegressor(min_samples_split=5, min_samples_leaf=2, max_depth=40)),\n",
    "    ('random_forest', RandomForestRegressor(n_estimators=200, min_samples_split=5, min_samples_leaf=1, max_features='auto', \n",
    "                                            max_depth=20)),\n",
    "    ('adaboost', AdaBoostRegressor(n_estimators=200, learning_rate=0.1)),\n",
    "    ('xgboost', XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.3))\n",
    "]\n",
    "\n",
    "def stacking(model1, model2):\n",
    "    # Define base models\n",
    "    base_models = [\n",
    "        model1,\n",
    "        model2\n",
    "    ]\n",
    "\n",
    "    # Define the final estimator\n",
    "    final_estimator = BayesianRidge()\n",
    "\n",
    "    stacking_regressor = StackingRegressor(\n",
    "        estimators=base_models,\n",
    "        final_estimator=final_estimator,\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    # Fit the stacking regressor\n",
    "    stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = stacking_regressor.predict(X_train)\n",
    "    y_test_pred = stacking_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate and print RMSE for training and test sets\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "    print(f\"Stacking Regressor ({model1[0]}, {model2[0]})\")\n",
    "    print(f\"Training RMSE: {rmse_train}\")\n",
    "    print(f\"Test RMSE: {rmse_test}\")\n",
    "    \n",
    "    return stacking_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bbde2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor (linear_regression, decision_tree)\n",
      "Training RMSE: 0.012856917013167143\n",
      "Test RMSE: 0.04039601602018947\n",
      "Stacking Regressor (linear_regression, random_forest)\n",
      "Training RMSE: 0.01796742585872388\n",
      "Test RMSE: 0.04082923539530012\n",
      "Stacking Regressor (linear_regression, adaboost)\n",
      "Training RMSE: 0.35162737016167417\n",
      "Test RMSE: 0.35261697371278744\n",
      "Stacking Regressor (linear_regression, xgboost)\n",
      "Training RMSE: 0.025306229958244712\n",
      "Test RMSE: 0.04786314433627748\n",
      "Stacking Regressor (decision_tree, random_forest)\n",
      "Training RMSE: 0.013908415880310797\n",
      "Test RMSE: 0.036400723030542155\n",
      "Stacking Regressor (decision_tree, adaboost)\n",
      "Training RMSE: 0.012647847633067017\n",
      "Test RMSE: 0.0478242012922004\n",
      "Stacking Regressor (decision_tree, xgboost)\n",
      "Training RMSE: 0.014897001307021745\n",
      "Test RMSE: 0.035464537469928836\n",
      "Stacking Regressor (random_forest, adaboost)\n",
      "Training RMSE: 0.017899056343992786\n",
      "Test RMSE: 0.04049918692497505\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for j in range(i+1, 5):\n",
    "        stacking(models[i], models[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7117768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor (random_forest, xgboost)\n",
      "Training RMSE: 0.015860156339435858\n",
      "Test RMSE: 0.03681153387845069\n",
      "-------------------\n",
      "Stacking Regressor (adaboost, xgboost)\n",
      "Training RMSE: 0.02533911947869533\n",
      "Test RMSE: 0.047770816638629456\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(cv=5,\n",
       "                  estimators=[(&#x27;adaboost&#x27;,\n",
       "                               AdaBoostRegressor(learning_rate=0.1,\n",
       "                                                 n_estimators=200)),\n",
       "                              (&#x27;xgboost&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gr...\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.3, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=6,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=300, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...))],\n",
       "                  final_estimator=BayesianRidge())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(cv=5,\n",
       "                  estimators=[(&#x27;adaboost&#x27;,\n",
       "                               AdaBoostRegressor(learning_rate=0.1,\n",
       "                                                 n_estimators=200)),\n",
       "                              (&#x27;xgboost&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gr...\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.3, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=6,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=300, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...))],\n",
       "                  final_estimator=BayesianRidge())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>adaboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(learning_rate=0.1, n_estimators=200)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesianRidge</label><div class=\"sk-toggleable__content\"><pre>BayesianRidge()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(cv=5,\n",
       "                  estimators=[('adaboost',\n",
       "                               AdaBoostRegressor(learning_rate=0.1,\n",
       "                                                 n_estimators=200)),\n",
       "                              ('xgboost',\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gr...\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.3, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=6,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=300, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...))],\n",
       "                  final_estimator=BayesianRidge())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_stacking_model = stacking(models[2], models[4])\n",
    "print(\"-------------------\")\n",
    "stacking(models[3], models[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fefba4f",
   "metadata": {},
   "source": [
    "Still overfitting. Try to simplify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3065954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor (decision_tree, xgboost)\n",
      "Training RMSE: 0.020310341572631545\n",
      "Test RMSE: 0.036844116791883055\n"
     ]
    }
   ],
   "source": [
    "model_1 = ('decision_tree', DecisionTreeRegressor(min_samples_split=5, min_samples_leaf=2, max_depth=30))\n",
    "model_2 = ('xgboost', XGBRegressor(n_estimators=300, max_depth=4, learning_rate=0.3, reg_alpha=0.01,\n",
    "                                   reg_lambda=0.02, subsample=0.8, colsample_bytree=0.8))\n",
    "best_model = stacking(model_1, model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db12efe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_model.joblib\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "model_filename = 'trained_model.joblib'\n",
    "dump(best_model, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b77eec",
   "metadata": {},
   "source": [
    "## Performance Improvement - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bc7c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "loaded_model = load('trained_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c326b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def model_training(X_train, X_test, y_train, y_test):\n",
    "    base_models = [\n",
    "        ('decision_tree', DecisionTreeRegressor(min_samples_split=5, min_samples_leaf=2, max_depth=30)),\n",
    "        ('xgboost', XGBRegressor(n_estimators=300, max_depth=4, learning_rate=0.3, reg_alpha=0.01,\n",
    "                                 reg_lambda=0.02, subsample=0.8, colsample_bytree=0.8))\n",
    "    ]\n",
    "\n",
    "    # Define the final estimator\n",
    "    final_estimator = BayesianRidge()\n",
    "\n",
    "    stacking_regressor = StackingRegressor(\n",
    "        estimators=base_models,\n",
    "        final_estimator=final_estimator,\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    # Fit the stacking regressor\n",
    "    stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = stacking_regressor.predict(X_train)\n",
    "    y_test_pred = stacking_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate and print RMSE for training and test sets\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "    print(f\"Training RMSE: {rmse_train}\")\n",
    "    print(f\"Test RMSE: {rmse_test}\")\n",
    "    \n",
    "    return stacking_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf63647",
   "metadata": {},
   "source": [
    "bin the 'review_count_x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "743729c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        review_count_x  binned_review_count_x\n",
      "0                 3834                      5\n",
      "1                 3834                      5\n",
      "2                 3834                      5\n",
      "3                 3834                      5\n",
      "4                 3834                      5\n",
      "...                ...                    ...\n",
      "162278               7                      0\n",
      "162279               7                      0\n",
      "162280               7                      0\n",
      "162281               7                      0\n",
      "162282               7                      0\n",
      "\n",
      "[162283 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = data[['review_count_x']]\n",
    "\n",
    "# Define bins\n",
    "bins = [0, 100, 200, 500, 1000, 2000, 100000000]\n",
    "\n",
    "# Bin the data\n",
    "df['binned_review_count_x'] = pd.cut(df['review_count_x'], bins=bins, labels=False, right=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1cd9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['binned_review_count_x'] = df['binned_review_count_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f026ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = ['postal_code', 'is_open', 'RestaurantsTakeOut', 'NoiseLevel', 'Caters', 'RestaurantsReservations',\n",
    "           'BusinessAcceptsCreditCards', 'GoodForKids', 'RestaurantsPriceRange2',\n",
    "           'OutdoorSeating', 'RestaurantsDelivery', 'HasTV', 'RestaurantsAttire',\n",
    "           'Alcohol', 'RestaurantsGoodForGroups', 'BikeParking', 'WiFi',\n",
    "           'BusinessParking_garage', 'BusinessParking_street',\n",
    "           'BusinessParking_validated', 'BusinessParking_lot',\n",
    "           'BusinessParking_valet', 'Ambience_touristy', 'Ambience_hipster',\n",
    "           'Ambience_romantic', 'Ambience_divey', 'Ambience_intimate',\n",
    "           'Ambience_trendy', 'Ambience_upscale', 'Ambience_classy',\n",
    "           'Ambience_casual', 'GoodForMeal_dessert', 'GoodForMeal_latenight',\n",
    "           'GoodForMeal_lunch', 'GoodForMeal_dinner', 'GoodForMeal_brunch',\n",
    "           'GoodForMeal_breakfast', 'category_Casual Dining & Drinks',\n",
    "           'category_Diverse Cuisine & Entertainment',\n",
    "           'category_Health & Lifestyle', 'category_Nightlife Essentials',\n",
    "           'category_Traditional Comfort Foods', 'category_Sophisticated Eats', 'binned_review_count_x']\n",
    "num_var = ['review_count_x', 'stars_y', 'useful_x', 'funny_x', 'cool_x',\n",
    "           'review_count_y', 'useful_y', 'funny_y', 'cool_y', 'fans',\n",
    "           'average_stars', 'compliment_hot', 'compliment_more',\n",
    "           'compliment_profile', 'compliment_cute', 'compliment_list',\n",
    "           'compliment_funny', 'compliment_writer', 'compliment_photos', 'days_used',\n",
    "           '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
    "           '11', '12', '13', '14', '15', '16', '17', '18', '19']\n",
    "\n",
    "# transform categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = pd.concat([data[cat_var].astype(str), data[num_var]], axis=1)\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoder.fit(X[cat_var])\n",
    "\n",
    "encoded_cols = encoder.get_feature_names_out(cat_var)\n",
    "X[encoded_cols] = encoder.transform(X[cat_var])\n",
    "X.drop(columns=cat_var, inplace=True)\n",
    "\n",
    "y = data[['stars_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "198680a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73d76fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 0.02074254679772098\n",
      "Test RMSE: 0.03574559179054801\n"
     ]
    }
   ],
   "source": [
    "model_binned_review_count = model_training(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f91c726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_model.joblib\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "model_filename = 'trained_model.joblib'\n",
    "dump(model_binned_review_count, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a5103",
   "metadata": {},
   "source": [
    "user attributes: reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5338d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = data[['compliment_hot', 'compliment_more',\n",
    "      'compliment_profile', 'compliment_cute', 'compliment_list',\n",
    "      'compliment_funny', 'compliment_writer', 'compliment_photos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20478697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>381.960740</td>\n",
       "      <td>253.597483</td>\n",
       "      <td>151.267998</td>\n",
       "      <td>-74.427472</td>\n",
       "      <td>-14.302966</td>\n",
       "      <td>-3.480313</td>\n",
       "      <td>-14.323556</td>\n",
       "      <td>5.567945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.971017</td>\n",
       "      <td>-2.821597</td>\n",
       "      <td>3.065343</td>\n",
       "      <td>-2.233410</td>\n",
       "      <td>0.281798</td>\n",
       "      <td>-0.184740</td>\n",
       "      <td>0.052179</td>\n",
       "      <td>0.027619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.202471</td>\n",
       "      <td>6.964694</td>\n",
       "      <td>3.355006</td>\n",
       "      <td>2.651539</td>\n",
       "      <td>0.687575</td>\n",
       "      <td>0.875187</td>\n",
       "      <td>-0.451867</td>\n",
       "      <td>-0.517745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.618928</td>\n",
       "      <td>23.728543</td>\n",
       "      <td>25.304195</td>\n",
       "      <td>-15.719786</td>\n",
       "      <td>0.382399</td>\n",
       "      <td>1.145297</td>\n",
       "      <td>1.250362</td>\n",
       "      <td>1.257002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162278</th>\n",
       "      <td>0.565727</td>\n",
       "      <td>0.199062</td>\n",
       "      <td>-0.740686</td>\n",
       "      <td>0.290059</td>\n",
       "      <td>-0.076687</td>\n",
       "      <td>0.037238</td>\n",
       "      <td>-0.011807</td>\n",
       "      <td>-0.013071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162279</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162280</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162281</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162282</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162283 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0           1           2          3          4         5  \\\n",
       "0       381.960740  253.597483  151.267998 -74.427472 -14.302966 -3.480313   \n",
       "1         7.971017   -2.821597    3.065343  -2.233410   0.281798 -0.184740   \n",
       "2         0.000000    0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "3        11.202471    6.964694    3.355006   2.651539   0.687575  0.875187   \n",
       "4        57.618928   23.728543   25.304195 -15.719786   0.382399  1.145297   \n",
       "...            ...         ...         ...        ...        ...       ...   \n",
       "162278    0.565727    0.199062   -0.740686   0.290059  -0.076687  0.037238   \n",
       "162279    0.000000    0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "162280    0.000000    0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "162281    0.000000    0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "162282    0.000000    0.000000    0.000000   0.000000   0.000000  0.000000   \n",
       "\n",
       "                6         7  \n",
       "0      -14.323556  5.567945  \n",
       "1        0.052179  0.027619  \n",
       "2        0.000000  0.000000  \n",
       "3       -0.451867 -0.517745  \n",
       "4        1.250362  1.257002  \n",
       "...           ...       ...  \n",
       "162278  -0.011807 -0.013071  \n",
       "162279   0.000000  0.000000  \n",
       "162280   0.000000  0.000000  \n",
       "162281   0.000000  0.000000  \n",
       "162282   0.000000  0.000000  \n",
       "\n",
       "[162283 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=8)\n",
    "X_reduced = svd.fit_transform(sparse_features)\n",
    "X_reduced = pd.DataFrame(X_reduced)\n",
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af620d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced.columns = [f\"reduced_{i}\" for i in range(8)]\n",
    "data = pd.concat([data, X_reduced], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b39781ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = ['postal_code', 'is_open', 'RestaurantsTakeOut', 'NoiseLevel', 'Caters', 'RestaurantsReservations',\n",
    "           'BusinessAcceptsCreditCards', 'GoodForKids', 'RestaurantsPriceRange2',\n",
    "           'OutdoorSeating', 'RestaurantsDelivery', 'HasTV', 'RestaurantsAttire',\n",
    "           'Alcohol', 'RestaurantsGoodForGroups', 'BikeParking', 'WiFi',\n",
    "           'BusinessParking_garage', 'BusinessParking_street',\n",
    "           'BusinessParking_validated', 'BusinessParking_lot',\n",
    "           'BusinessParking_valet', 'Ambience_touristy', 'Ambience_hipster',\n",
    "           'Ambience_romantic', 'Ambience_divey', 'Ambience_intimate',\n",
    "           'Ambience_trendy', 'Ambience_upscale', 'Ambience_classy',\n",
    "           'Ambience_casual', 'GoodForMeal_dessert', 'GoodForMeal_latenight',\n",
    "           'GoodForMeal_lunch', 'GoodForMeal_dinner', 'GoodForMeal_brunch',\n",
    "           'GoodForMeal_breakfast', 'category_Casual Dining & Drinks',\n",
    "           'category_Diverse Cuisine & Entertainment',\n",
    "           'category_Health & Lifestyle', 'category_Nightlife Essentials',\n",
    "           'category_Traditional Comfort Foods', 'category_Sophisticated Eats', 'binned_review_count_x']\n",
    "num_var = ['review_count_x', 'stars_y', 'useful_x', 'funny_x', 'cool_x',\n",
    "           'review_count_y', 'useful_y', 'funny_y', 'cool_y', 'fans',\n",
    "           'average_stars', 'days_used',\n",
    "           '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
    "           '11', '12', '13', '14', '15', '16', '17', '18', '19', 'reduced_0', 'reduced_1', 'reduced_2', 'reduced_3',\n",
    "           'reduced_4', 'reduced_5', 'reduced_6', 'reduced_7']\n",
    "\n",
    "# transform categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = pd.concat([data[cat_var].astype(str), data[num_var]], axis=1)\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoder.fit(X[cat_var])\n",
    "\n",
    "encoded_cols = encoder.get_feature_names_out(cat_var)\n",
    "X[encoded_cols] = encoder.transform(X[cat_var])\n",
    "X.drop(columns=cat_var, inplace=True)\n",
    "\n",
    "y = data[['stars_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58160c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f010aa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 0.021850588018266025\n",
      "Test RMSE: 0.03763510484116766\n"
     ]
    }
   ],
   "source": [
    "model_reduced_features = model_training(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ebcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
